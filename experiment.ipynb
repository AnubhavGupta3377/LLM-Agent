{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = \"gemma3:4b\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"local-llm-rag-gemma3-4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Downloading: 100%|██████████| 274M/274M [00:14<00:00, 18.4MiB/s] \n",
      "Verifying: 100%|██████████| 274M/274M [00:00<00:00, 611MiB/s] \n",
      "Embedding texts: 100%|██████████| 47/47 [00:18<00:00,  2.55inputs/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Cricket\",\n",
    "    \"https://en.wikipedia.org/wiki/Cricket_World_Cup\",\n",
    "    \"https://en.wikipedia.org/wiki/List_of_Cricket_World_Cup_records\",\n",
    "    \"https://en.wikipedia.org/wiki/List_of_Test_cricket_records\",\n",
    "    \"https://en.wikipedia.org/wiki/List_of_One_Day_International_cricket_records\",\n",
    "    \"https://en.wikipedia.org/wiki/List_of_Twenty20_International_records\"\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"gpt2\", chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'websearch'} {'datasource': 'vectorstore'} {'datasource': 'websearch'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prompt\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to Cricket and cricket records.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with single key, datasource, that is 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Test router\n",
    "test_web_search = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [\n",
    "        HumanMessage(\n",
    "            content=\"What are large language models?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "test_web_search_2 = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"Who is Sachin Tendulkar?\")]\n",
    ")\n",
    "test_vector_store = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"When did world war II end?\")]\n",
    ")\n",
    "print(\n",
    "    json.loads(test_web_search.content),\n",
    "    json.loads(test_web_search_2.content),\n",
    "    json.loads(test_vector_store.content),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
